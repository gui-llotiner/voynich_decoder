{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bf7fbc9-5f04-4a58-aabe-2f63d2b91793",
   "metadata": {},
   "source": [
    "### Phonotatic Constraits Analysis\n",
    "\n",
    "Atempt of morphological decipherement (via phonotatic constraits) based on the hypothesis of Naibbe Cipher: https://youtu.be/ByARtG-GUPo?t=5559"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e5ba215-a7b7-4093-9cd8-5fb0af352069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folio</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1r</td>\n",
       "      <td>fachys ykal ar ataiin shol shory cthres kor sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1r</td>\n",
       "      <td>sory ckhar or kair chtaiin shar ase cthar ctha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1r</td>\n",
       "      <td>syaiir sheky or ykaiin shod cthoary cthes dara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1r</td>\n",
       "      <td>soiin oteey oteos roloty cthiar daiin okaiin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1r</td>\n",
       "      <td>sair chear cthaiin cphar cfhaiin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>116r</td>\n",
       "      <td>osain shky qorain chckhey qokey lkechy okeey o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303</th>\n",
       "      <td>116r</td>\n",
       "      <td>sykar ain olkeey dainchey qokar chey dain otan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5304</th>\n",
       "      <td>116r</td>\n",
       "      <td>sysor shey qokey okeolan chey qol or cheey qor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5305</th>\n",
       "      <td>116r</td>\n",
       "      <td>sodal ch al chcthy chckhy qol ain ary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>116v</td>\n",
       "      <td>oror sheey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5307 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     folio                                               text\n",
       "0       1r  fachys ykal ar ataiin shol shory cthres kor sh...\n",
       "1       1r  sory ckhar or kair chtaiin shar ase cthar ctha...\n",
       "2       1r  syaiir sheky or ykaiin shod cthoary cthes dara...\n",
       "3       1r  soiin oteey oteos roloty cthiar daiin okaiin o...\n",
       "4       1r                   sair chear cthaiin cphar cfhaiin\n",
       "...    ...                                                ...\n",
       "5302  116r  osain shky qorain chckhey qokey lkechy okeey o...\n",
       "5303  116r  sykar ain olkeey dainchey qokar chey dain otan...\n",
       "5304  116r  sysor shey qokey okeolan chey qol or cheey qor...\n",
       "5305  116r              sodal ch al chcthy chckhy qol ain ary\n",
       "5306  116v                                         oror sheey\n",
       "\n",
       "[5307 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "class VoynichTextProcessor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.raw_text = None\n",
    "\n",
    "    def load_raw_text(self, filepath: str) -> bool:\n",
    "        \"\"\"Load raw text from file.\"\"\"\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                self.raw_text = f.read()\n",
    "            return True\n",
    "        except FileNotFoundError:\n",
    "            return False\n",
    "\n",
    "    def clean_voynich_text(self, filepath: str, treat_commas_as_spaces: bool = True, min_word_length: int = 2) -> pd.DataFrame:\n",
    "        \"\"\"Clean Voynich Manuscript text and return a DataFrame\"\"\"\n",
    "        if not self.load_raw_text(filepath):\n",
    "            return pd.DataFrame(columns=['folio', 'text'])\n",
    "\n",
    "        lines = self.raw_text.strip().split('\\n')\n",
    "        folio_pattern = r'<f(\\d+)([rv])?\\.'\n",
    "        data = []\n",
    "        current_folio = None\n",
    "\n",
    "        def replace_uncertain(match):\n",
    "            options = match.group(1).split(':')\n",
    "            return options[0] if options else ''\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith('#'):\n",
    "                continue\n",
    "\n",
    "            cleaned_line = line\n",
    "            cleaned_line = re.sub(r'@\\d+', '', cleaned_line)  # Remove annotations\n",
    "            cleaned_line = re.sub(r'<![^>]*>', '', cleaned_line)  # Remove comments\n",
    "            cleaned_line = re.sub(r'<[^>]*>', '', cleaned_line)  # Remove other markup\n",
    "            cleaned_line = re.sub(r'\\[([^\\]]+)\\]', replace_uncertain, cleaned_line)  # Handle uncertain readings\n",
    "            cleaned_line = re.sub(r'[{}]', '', cleaned_line)  # Remove braces\n",
    "            cleaned_line = re.sub(r'\\?+', '', cleaned_line)  # Remove question marks\n",
    "            cleaned_line = re.sub(r'[^a-zA-Z\\s,.]', '', cleaned_line)  # Keep only letters, spaces, commas, periods\n",
    "            if treat_commas_as_spaces:\n",
    "                cleaned_line = cleaned_line.replace('.', ' ').replace(',', ' ')\n",
    "            else:\n",
    "                cleaned_line = cleaned_line.replace('.', ' ').replace(',', '')\n",
    "            cleaned_line = re.sub(r'\\s+', ' ', cleaned_line).strip().lower()  # Normalize spaces, lowercase\n",
    "\n",
    "            folio_match = re.search(folio_pattern, line)\n",
    "            if folio_match:\n",
    "                current_folio = f\"{folio_match.group(1)}{folio_match.group(2) or 'r'}\"\n",
    "            elif re.match(folio_pattern, cleaned_line):\n",
    "                continue\n",
    "\n",
    "            if cleaned_line and current_folio:\n",
    "                words = cleaned_line.split()\n",
    "                clean_words = [w for w in words if re.match(r'^[a-z]+$', w) and len(w) >= min_word_length]\n",
    "                if clean_words:\n",
    "                    data.append({'folio': current_folio, 'text': ' '.join(clean_words)})\n",
    "\n",
    "        text = pd.DataFrame(data, columns=['folio', 'text'])\n",
    "        return text\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processor = VoynichTextProcessor()\n",
    "    filepath = \"transliteration_zl.txt\"\n",
    "    text = processor.clean_voynich_text(filepath)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8e3af7-262f-4dbe-aee7-1efb6779d047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>sequence</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>3</td>\n",
       "      <td>chol chol kor</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>3</td>\n",
       "      <td>chol daiin cthy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>3</td>\n",
       "      <td>daiin cthy schey</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>3</td>\n",
       "      <td>chol chy chaiin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>3</td>\n",
       "      <td>cthor chol chor</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2</td>\n",
       "      <td>shol daiin</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2</td>\n",
       "      <td>otol chol</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>chor daiin</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2</td>\n",
       "      <td>daiin dain</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2</td>\n",
       "      <td>or aiin</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     n          sequence  count\n",
       "348  3     chol chol kor      2\n",
       "349  3   chol daiin cthy      2\n",
       "350  3  daiin cthy schey      2\n",
       "351  3   chol chy chaiin      2\n",
       "352  3   cthor chol chor      2\n",
       "..  ..               ...    ...\n",
       "84   2        shol daiin      7\n",
       "88   2         otol chol      7\n",
       "102  2        chor daiin      8\n",
       "161  2        daiin dain      9\n",
       "138  2           or aiin     13\n",
       "\n",
       "[332 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def get_folio_number(folio):\n",
    "    \"\"\"Extract numeric part of folio (e.g., '1r' -> 1).\"\"\"\n",
    "    match = re.match(r'(\\d+)', folio)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "def generate_ngrams(words, n):\n",
    "    \"\"\"Generate n-grams from a list of words.\"\"\"\n",
    "    return [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "\n",
    "def find_ngram_frequencies(text_df, max_n=10):\n",
    "    \"\"\"Return a DataFrame with longest n-grams (2 to max_n) with frequencies >1 for folios 1 to 60.\"\"\"\n",
    "    # Filter for folios 1 to 60\n",
    "    filtered_text = text_df[text_df['folio'].apply(get_folio_number) <= 55]\n",
    "    \n",
    "    # Concatenate all text into one list of words\n",
    "    all_words = ' '.join(filtered_text['text'].fillna('').tolist()).split()\n",
    "    \n",
    "    # Collect n-gram data\n",
    "    ngram_data = []\n",
    "    \n",
    "    # Generate and count n-grams for n=2 to max_n\n",
    "    for n in range(2, max_n + 1):\n",
    "        ngrams = generate_ngrams(all_words, n)\n",
    "        ngram_counts = Counter(ngrams)\n",
    "        # Only include n-grams with count > 1\n",
    "        for seq, count in ngram_counts.items():\n",
    "            if count > 1:\n",
    "                ngram_data.append({'n': n, 'sequence': seq, 'count': count})\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(ngram_data, columns=['n', 'sequence', 'count'])\n",
    "    \n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    # Filter out shorter n-grams contained in longer ones\n",
    "    longest_ngrams = []\n",
    "    for n in range(max_n, 1, -1):  # Start with longest n-grams\n",
    "        current_ngrams = df[df['n'] == n]\n",
    "        for _, row in current_ngrams.iterrows():\n",
    "            seq = row['sequence']\n",
    "            is_subsequence = False\n",
    "            # Check if this sequence is contained in any longer n-gram\n",
    "            for _, longer_row in df[df['n'] > n].iterrows():\n",
    "                if seq in longer_row['sequence']:\n",
    "                    is_subsequence = True\n",
    "                    break\n",
    "            if not is_subsequence:\n",
    "                longest_ngrams.append(row)\n",
    "    \n",
    "    # Create final DataFrame with only longest n-grams\n",
    "    result_df = pd.DataFrame(longest_ngrams, columns=['n', 'sequence', 'count'])\n",
    "    return result_df.sort_values(by=['n', 'count'], ascending=[False, True])\n",
    "\n",
    "ngram_df = find_ngram_frequencies(text, max_n=10)\n",
    "ngram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4b1eeb3-b360-4247-95c0-b1753a4a5d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folio</th>\n",
       "      <th>sequence</th>\n",
       "      <th>length</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10v, 14v, 15r, 15v, 16v, 19v, 1v, 20v, 21r, 21...</td>\n",
       "      <td>chol daiin</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15v, 17v, 1r, 29v, 42r, 44v, 45r, 47r, 47v, 54...</td>\n",
       "      <td>chol chol</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>10r, 20v, 31v, 33r, 33v, 39v, 40r, 43v, 55r, 58v</td>\n",
       "      <td>or aiin</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>11r, 15v, 22v, 32r, 3r, 44v, 45v, 51v, 9v</td>\n",
       "      <td>daiin cthy</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>15v, 20v, 22v, 25v, 42r, 47r, 56v, 5v</td>\n",
       "      <td>shol daiin</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>43r</td>\n",
       "      <td>yty oty</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>46v</td>\n",
       "      <td>oty qoty</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>49r</td>\n",
       "      <td>daiin dor</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>55r</td>\n",
       "      <td>daiin sho</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>55v</td>\n",
       "      <td>aiin daiin</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>611 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 folio    sequence  length  \\\n",
       "33   10v, 14v, 15r, 15v, 16v, 19v, 1v, 20v, 21r, 21...  chol daiin       2   \n",
       "10   15v, 17v, 1r, 29v, 42r, 44v, 45r, 47r, 47v, 54...   chol chol       2   \n",
       "173   10r, 20v, 31v, 33r, 33v, 39v, 40r, 43v, 55r, 58v     or aiin       2   \n",
       "63           11r, 15v, 22v, 32r, 3r, 44v, 45v, 51v, 9v  daiin cthy       2   \n",
       "109              15v, 20v, 22v, 25v, 42r, 47r, 56v, 5v  shol daiin       2   \n",
       "..                                                 ...         ...     ...   \n",
       "550                                                43r     yty oty       2   \n",
       "571                                                46v    oty qoty       2   \n",
       "587                                                49r   daiin dor       2   \n",
       "605                                                55r   daiin sho       2   \n",
       "607                                                55v  aiin daiin       2   \n",
       "\n",
       "     frequency  \n",
       "33          26  \n",
       "10          18  \n",
       "173         14  \n",
       "63           9  \n",
       "109          8  \n",
       "..         ...  \n",
       "550          1  \n",
       "571          1  \n",
       "587          1  \n",
       "605          1  \n",
       "607          1  \n",
       "\n",
       "[611 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "\n",
    "def create_transitions_df(ngram_df):\n",
    "    \"\"\"Generate transitions_df from all n-grams in ngram_df.\"\"\"\n",
    "    # Collect all consecutive word pairs from n-grams\n",
    "    transitions = []\n",
    "    for _, row in ngram_df.iterrows():\n",
    "        words = row['sequence'].split()\n",
    "        # Extract consecutive pairs from the n-gram\n",
    "        for i in range(len(words) - 1):\n",
    "            first_word = words[i]\n",
    "            second_word = words[i + 1]\n",
    "            transitions.append((first_word, second_word))\n",
    "    \n",
    "    # Convert to DataFrame and group by first word to get successors\n",
    "    transitions_df = pd.DataFrame(transitions, columns=['first_word', 'second_word'])\n",
    "    transitions_df = transitions_df.groupby('first_word')['second_word'].apply(\n",
    "        lambda x: ', '.join(sorted(set(x)))\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Rename columns to match expected format\n",
    "    transitions_df.columns = ['symbol', 'successors']\n",
    "    return transitions_df\n",
    "\n",
    "def map_valid_sequences(text_df, transitions_df, max_n=10):\n",
    "    \"\"\"Identify valid sequences based on transitions_df.\"\"\"\n",
    "    def get_folio_number(folio):\n",
    "        match = re.match(r'(\\d+)', folio)\n",
    "        return int(match.group(1)) if match else 0\n",
    "    \n",
    "    filtered_text = text_df[text_df['folio'].apply(get_folio_number) <= 60]\n",
    "    \n",
    "    successor_dict = {row['symbol']: set(row['successors'].split(', ')) if row['successors'] else set() \n",
    "                      for _, row in transitions_df.iterrows()}\n",
    "    \n",
    "    sequence_folios = defaultdict(list)\n",
    "    sequence_counts = Counter()\n",
    "    \n",
    "    for _, row in filtered_text.iterrows():\n",
    "        folio = row['folio']\n",
    "        words = row['text'].split()\n",
    "        if len(words) < 2:\n",
    "            continue\n",
    "        for n in range(2, min(max_n + 1, len(words) + 1)):\n",
    "            for i in range(len(words) - n + 1):\n",
    "                subsequence = words[i:i+n]\n",
    "                is_valid = True\n",
    "                for j in range(len(subsequence) - 1):\n",
    "                    current = subsequence[j]\n",
    "                    next_word = subsequence[j + 1]\n",
    "                    if current not in successor_dict or next_word not in successor_dict[current]:\n",
    "                        is_valid = False\n",
    "                        break\n",
    "                if is_valid:\n",
    "                    seq_str = ' '.join(subsequence)\n",
    "                    sequence_counts[seq_str] += 1\n",
    "                    if folio not in sequence_folios[seq_str]:\n",
    "                        sequence_folios[seq_str].append(folio)\n",
    "    \n",
    "    valid_sequences = []\n",
    "    for seq, folios in sequence_folios.items():\n",
    "        valid_sequences.append({\n",
    "            'folio': ', '.join(sorted(folios)),\n",
    "            'sequence': seq,\n",
    "            'length': len(seq.split()),\n",
    "            'frequency': sequence_counts[seq]\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(valid_sequences)\n",
    "    if df.empty:\n",
    "        return df\n",
    "    return df.sort_values(by=['frequency', 'length'], ascending=[False, False])\n",
    "\n",
    "# Generate transitions_df from ngram_df\n",
    "transitions_df = create_transitions_df(ngram_df)\n",
    "\n",
    "# Run the function\n",
    "valid_sequences_df = map_valid_sequences(text, transitions_df)\n",
    "valid_sequences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68bafd1d-ba09-41a7-ad38-7be9b47ae88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram_type</th>\n",
       "      <th>bigram</th>\n",
       "      <th>rule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>observed</td>\n",
       "      <td>aiin-char</td>\n",
       "      <td>(L²){5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>observed</td>\n",
       "      <td>aiin-cthol</td>\n",
       "      <td>(L²){5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>observed</td>\n",
       "      <td>aiin-daiin</td>\n",
       "      <td>(L²){5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>observed</td>\n",
       "      <td>aiin-dal</td>\n",
       "      <td>(L²){5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>observed</td>\n",
       "      <td>aiin-dol</td>\n",
       "      <td>(L²){5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24331</th>\n",
       "      <td>absent</td>\n",
       "      <td>yty-ykeey</td>\n",
       "      <td>(L²){5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24332</th>\n",
       "      <td>absent</td>\n",
       "      <td>yty-yodaiin</td>\n",
       "      <td>(L²){5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24333</th>\n",
       "      <td>absent</td>\n",
       "      <td>yty-ytchy</td>\n",
       "      <td>(L²){5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24334</th>\n",
       "      <td>absent</td>\n",
       "      <td>yty-ytedy</td>\n",
       "      <td>(L²){5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24335</th>\n",
       "      <td>absent</td>\n",
       "      <td>yty-yty</td>\n",
       "      <td>(L²){5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24336 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bigram_type       bigram     rule\n",
       "0        observed    aiin-char  (L²){5}\n",
       "1        observed   aiin-cthol  (L²){5}\n",
       "2        observed   aiin-daiin  (L²){5}\n",
       "3        observed     aiin-dal  (L²){5}\n",
       "4        observed     aiin-dol  (L²){5}\n",
       "...           ...          ...      ...\n",
       "24331      absent    yty-ykeey  (L²){5}\n",
       "24332      absent  yty-yodaiin  (L²){5}\n",
       "24333      absent    yty-ytchy  (L²){5}\n",
       "24334      absent    yty-ytedy  (L²){5}\n",
       "24335      absent      yty-yty  (L²){5}\n",
       "\n",
       "[24336 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Set, Tuple, List\n",
    "import pandas as pd\n",
    "\n",
    "def extract_symbol_bigrams(symbols: List[str]) -> Set[str]:\n",
    "    \"\"\"Extract unique bigrams of symbols from a list of symbols.\"\"\"\n",
    "    bigrams = {f\"{symbols[i]}-{symbols[i+1]}\" for i in range(len(symbols) - 1)}\n",
    "    return bigrams\n",
    "\n",
    "def get_absent_symbol_bigrams(symbols: List[str], observed_bigrams: Set[str]) -> Set[str]:\n",
    "    \"\"\"Get all possible symbol bigrams not observed in the data.\"\"\"\n",
    "    alphabet = set(symbols)\n",
    "    all_possible_bigrams = {f\"{a}-{b}\" for a in alphabet for b in alphabet}\n",
    "    return all_possible_bigrams - observed_bigrams\n",
    "\n",
    "def find_longest_symbol_bigram_chain(symbols: List[str]) -> int:\n",
    "    \"\"\"Find the longest chain of bigrams where each shares a second symbol with the next's first.\"\"\"\n",
    "    if len(symbols) < 2:\n",
    "        return 0\n",
    "    max_chain = 1  # Minimum is one bigram\n",
    "    current_chain = 1\n",
    "    for i in range(len(symbols) - 2):\n",
    "        if symbols[i + 1] == symbols[i + 2]:  # Check if next bigram starts with current bigram's second symbol\n",
    "            current_chain += 1\n",
    "            max_chain = max(max_chain, current_chain)\n",
    "        else:\n",
    "            current_chain = 1\n",
    "    return max_chain\n",
    "\n",
    "def generate_symbol_bigram_rule(symbols: List[str]) -> str:\n",
    "    \"\"\"Generate a rule based on the longest chain of symbol bigrams.\"\"\"\n",
    "    max_chain = find_longest_symbol_bigram_chain(symbols)\n",
    "    if max_chain == 0:\n",
    "        return \"\"\n",
    "    return f\"(L²){{{max_chain}}}\"\n",
    "\n",
    "def process_voynich_symbol_sequences(valid_sequences_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process valid_sequences_df to extract symbol bigrams, absent bigrams, and a rule.\n",
    "    Returns a DataFrame with columns: bigram_type, bigram, rule.\n",
    "    \"\"\"\n",
    "    # Concatenate all sequences into a list of symbols\n",
    "    all_symbols = []\n",
    "    for seq in valid_sequences_df[\"sequence\"]:\n",
    "        symbols = seq.split()  # Split each sequence into symbols\n",
    "        all_symbols.extend(symbols)\n",
    "    \n",
    "    # Extract bigrams\n",
    "    observed_bigrams = extract_symbol_bigrams(all_symbols)\n",
    "    \n",
    "    # Get absent bigrams\n",
    "    absent_bigrams = get_absent_symbol_bigrams(all_symbols, observed_bigrams)\n",
    "    \n",
    "    # Generate rule\n",
    "    rule = generate_symbol_bigram_rule(all_symbols)\n",
    "    \n",
    "    # Create DataFrame for observed and absent bigrams\n",
    "    observed_rows = [{'bigram_type': 'observed', 'bigram': bigram, 'rule': rule} \n",
    "                     for bigram in sorted(observed_bigrams)]\n",
    "    absent_rows = [{'bigram_type': 'absent', 'bigram': bigram, 'rule': rule} \n",
    "                   for bigram in sorted(absent_bigrams)]\n",
    "    \n",
    "    # Combine into a single DataFrame\n",
    "    result_df = pd.DataFrame(observed_rows + absent_rows)\n",
    "    return result_df\n",
    "\n",
    "def main():\n",
    "    # Assume valid_sequences_df is available from map_valid_sequences\n",
    "    result_df = process_voynich_symbol_sequences(valid_sequences_df)\n",
    "    return result_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result_df = main()\n",
    "    result_df\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
